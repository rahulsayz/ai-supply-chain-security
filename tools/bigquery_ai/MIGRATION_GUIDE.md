# üîÑ Migration Guide: From Separate Processors to Unified AI Processor

## üìã Overview

This guide helps you migrate from the three separate AI processors to the new unified AI processor. The migration is designed to be **backward compatible**, so your existing code will continue to work while you gradually adopt the new unified approach.

## üéØ Migration Benefits

- **Single Entry Point** - One processor for all AI capabilities
- **Eliminated Confusion** - No more wondering which processor to use
- **Enhanced Features** - New comprehensive analysis pipeline
- **Better Performance** - Optimized query execution and resource management
- **Easier Maintenance** - Single codebase to maintain and update

## üîÑ What's Changing

### Before (3 Separate Processors)
```python
# You had to import and use different processors
from minimal_ai_processor import minimal_ai_processor
from ai_processor import ai_processor  
from ai_sql_processor import ai_sql_processor

# Different methods for different capabilities
minimal_ai_processor.analyze_threat("RPT001")
ai_processor.analyze_infrastructure("INFRA001")
ai_sql_processor.generate_threat_summary("description")
```

### After (1 Unified Processor)
```python
# Single import for all capabilities
from unified_ai_processor import unified_ai_processor

# All methods available from one processor
unified_ai_processor.analyze_threat("RPT001")
unified_ai_processor.analyze_multimodal_asset("INFRA001")
unified_ai_processor.generate_threat_summary("description")
```

## üöÄ Migration Steps

### Step 1: Update Imports

#### Old Code
```python
# Multiple imports
from minimal_ai_processor import minimal_ai_processor
from ai_processor import ai_processor
from ai_sql_processor import ai_sql_processor
```

#### New Code
```python
# Single import
from unified_ai_processor import unified_ai_processor
```

### Step 2: Update Method Calls

#### Threat Analysis
```python
# Old way
result = minimal_ai_processor.analyze_threat("RPT001")

# New way (still works!)
result = unified_ai_processor.analyze_threat("RPT001")

# Enhanced way
result = unified_ai_processor.generate_threat_summary("threat description")
```

#### Vendor Analysis
```python
# Old way
result = minimal_ai_processor.analyze_vendor("V001")

# New way (still works!)
result = unified_ai_processor.analyze_vendor("V001")

# Enhanced way
result = unified_ai_processor.generate_supply_chain_risk_assessment("vendor data")
```

#### Vector Search
```python
# Old way
result = minimal_ai_processor.perform_vector_search("RPT001")

# New way (still works!)
result = unified_ai_processor.perform_legacy_vector_search("RPT001")

# Enhanced way
result = unified_ai_processor.perform_vector_search("query text", "threats", 10)
```

### Step 3: Adopt New Features

#### Comprehensive Analysis
```python
# New unified approach
results = unified_ai_processor.run_comprehensive_supply_chain_analysis(
    threat_report_id="RPT001",
    query_text="supply chain security breach",
    asset_ids=["ASSET001", "ASSET002"]
)
```

#### AI SQL Functions
```python
# New AI capabilities
threat_intel = unified_ai_processor.generate_threat_intelligence("threat data")
forecast = unified_ai_processor.forecast_threat_metrics(days_ahead=60)
risk_assessment = unified_ai_processor.generate_supply_chain_risk_assessment("vendor data")
incident_plan = unified_ai_processor.generate_incident_response_plan("incident data")
```

#### Vector Operations
```python
# New vector capabilities
embeddings = unified_ai_processor.generate_embeddings_for_threats()
indexes = unified_ai_processor.create_vector_indexes()
clustering = unified_ai_processor.perform_semantic_clustering(cluster_count=5)
```

#### Multimodal Analysis
```python
# New multimodal capabilities
asset_analysis = unified_ai_processor.analyze_multimodal_asset("ASSET001")
upload_result = unified_ai_processor.upload_and_analyze_asset("file_path", asset_data)
```

## üîß API Migration

### Update Node.js Service Configuration

#### Old Configuration
```typescript
// src/services/bigquery-ai.service.ts
this.scriptPath = './tools/bigquery_ai/minimal_ai_processor.py';
```

#### New Configuration
```typescript
// src/services/bigquery_ai.service.ts
this.scriptPath = './tools/bigquery_ai/unified_ai_processor.py';
```

### API Endpoints Remain the Same

All existing API endpoints continue to work:
- `POST /api/bigquery-ai/analyze-threat`
- `POST /api/bigquery-ai/analyze-vendor`
- `POST /api/bigquery-ai/vector-search`
- `POST /api/bigquery-ai/export-data`

### New Enhanced Endpoints

Additional endpoints are now available:
- `POST /api/bigquery-ai/comprehensive-analysis`
- `POST /api/bigquery-ai/enhanced-vector-search`
- `POST /api/bigquery-ai/threat-intelligence`
- `POST /api/bigquery-ai/forecast-threats`

## üìä Migration Checklist

### ‚úÖ Phase 1: Basic Migration (Immediate)
- [ ] Update imports to use unified processor
- [ ] Verify existing method calls still work
- [ ] Test basic functionality
- [ ] Update Node.js service configuration

### ‚úÖ Phase 2: Feature Adoption (Week 1-2)
- [ ] Test new AI SQL functions
- [ ] Experiment with vector operations
- [ ] Try multimodal analysis
- [ ] Run comprehensive analysis demo

### ‚úÖ Phase 3: Optimization (Week 3-4)
- [ ] Replace legacy method calls with enhanced versions
- [ ] Implement comprehensive analysis pipeline
- [ ] Optimize query patterns
- [ ] Monitor performance improvements

### ‚úÖ Phase 4: Cleanup (Month 2)
- [ ] Remove old processor imports
- [ ] Update documentation
- [ ] Train team on new capabilities
- [ ] Plan future enhancements

## üß™ Testing Migration

### Test Existing Functionality
```python
from unified_ai_processor import unified_ai_processor

# Test legacy methods still work
assert unified_ai_processor.analyze_threat("RPT001") is not None
assert unified_ai_processor.analyze_vendor("V001") is not None
assert unified_ai_processor.perform_legacy_vector_search("RPT001") is not None

print("‚úÖ Legacy compatibility verified")
```

### Test New Functionality
```python
# Test new AI SQL functions
result = unified_ai_processor.generate_threat_summary("Test threat")
assert result.get("success") == True

# Test vector operations
result = unified_ai_processor.perform_vector_search("test query")
assert result.get("success") == True

# Test comprehensive analysis
result = unified_ai_processor.run_comprehensive_supply_chain_analysis(
    threat_report_id="RPT001"
)
assert result.get("success") == True

print("‚úÖ New functionality verified")
```

### Run Full Demo
```bash
cd tools/bigquery_ai
python unified_ai_processor.py --demo
```

## üö® Common Migration Issues

### Issue 1: Import Errors
**Problem**: `ModuleNotFoundError: No module named 'unified_ai_processor'`
**Solution**: Ensure you're in the correct directory and the file exists

### Issue 2: Method Not Found
**Problem**: `AttributeError: 'UnifiedAIProcessor' object has no attribute 'old_method'`
**Solution**: Check the migration guide for method name changes

### Issue 3: Configuration Errors
**Problem**: BigQuery connection or authentication issues
**Solution**: Verify service account credentials and project configuration

### Issue 4: Performance Issues
**Problem**: Queries running slower than expected
**Solution**: Check BigQuery quotas and enable query caching

## üîç Verification Commands

### Check Processor Status
```python
from unified_ai_processor import unified_ai_processor

# Verify processor is working
print(f"Processor available: {unified_ai_processor.isServiceAvailable()}")
print(f"Client initialized: {unified_ai_processor.client is not None}")
```

### Test Basic Operations
```python
# Test a simple AI query
result = unified_ai_processor.generate_threat_summary("Test threat description")
print(f"AI query result: {result.get('success')}")

# Test vector search
result = unified_ai_processor.perform_vector_search("test query")
print(f"Vector search result: {result.get('success')}")
```

### Verify API Integration
```bash
# Test Node.js service integration
curl -X POST http://localhost:3000/api/bigquery-ai/analyze-threat \
  -H "Content-Type: application/json" \
  -d '{"reportId": "RPT001"}'
```

## üìà Performance Comparison

### Before (Separate Processors)
- **Memory Usage**: 3 separate Python processes
- **Startup Time**: Multiple initialization delays
- **Code Duplication**: Shared functionality repeated
- **Maintenance**: 3 separate codebases to maintain

### After (Unified Processor)
- **Memory Usage**: Single optimized process
- **Startup Time**: Single initialization
- **Code Efficiency**: No duplication, shared resources
- **Maintenance**: Single codebase with clear structure

## üîÆ Post-Migration Benefits

### Immediate Benefits
- ‚úÖ Eliminated confusion about which processor to use
- ‚úÖ Single import for all AI capabilities
- ‚úÖ Backward compatibility maintained
- ‚úÖ Enhanced error handling and logging

### Long-term Benefits
- üöÄ Better performance through optimization
- üîß Easier maintenance and updates
- üìä Comprehensive analysis pipeline
- üí∞ Better cost management and monitoring
- üîí Enhanced security features

## üìû Support During Migration

### Resources
1. **This Migration Guide** - Step-by-step instructions
2. **Unified AI Processor README** - Complete documentation
3. **Demo Mode** - Test functionality with `--demo` flag
4. **Error Logs** - Detailed error reporting for debugging

### Getting Help
1. Check the troubleshooting section in the README
2. Run in debug mode for detailed logging
3. Test with demo data first
4. Verify configuration settings

## üéØ Migration Success Criteria

### Technical Success
- [ ] All existing functionality works
- [ ] New features are accessible
- [ ] Performance is maintained or improved
- [ ] Error handling is robust

### Operational Success
- [ ] Team can use unified processor
- [ ] Documentation is updated
- [ ] Training is completed
- [ ] Support processes are established

---

**üéâ Congratulations! You've successfully migrated to the Unified AI Processor and unlocked the full power of AI-powered supply chain security!**
